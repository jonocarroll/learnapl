{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing\n",
    "\n",
    "> Reminds me of the awesome bug report I saw once: ‘Everything is broken. Steps to reproduce: do anything. Expected result: it should work’. --_Felipe Knorr Kuhn_\n",
    "\n",
    "![bugs](./IMG/bugs.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=\"white-space:pre; font-family: monospace\">Was ON\n",
       "</span>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"white-space:pre; font-family: monospace\">Was OFF\n",
       "</span>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "⎕IO ← 0\n",
    "]box on\n",
    "]rows on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "APL programmers don't need to test their code, as they always write correct code. Next chapter...\n",
    "\n",
    "Ahem. Ninja master @ngn offered up the following [unit testing framework](https://ngn.bitbucket.io/apl/unit-test-framework.dyalog) on APL Orchard:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=\"white-space:pre; font-family: monospace\">≡\n",
       "</span>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "≡ ⍝ usage: expectedoutput ≡ f input.  prints 1 for ok and 0 for failure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whilst @ngn was (at least partially) joking, he's got a point. \n",
    "\n",
    "There is no official testing framework blessed by Dyalog. However, APL programmers do of course test their code. We can learn a lot from Dyalog's published source code. [Here](https://github.com/Dyalog/link/blob/master/StartupSession/Link/Test.dyalog), for example, is the test suite for the Link package. This is a fairly hefty namespace running to 2k+ LOC. If the code looks unfamiliar, it's because it's written in the tradfn style."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A 'framework'?\n",
    "\n",
    "No. But let's look at how unit testing is handled in other languages. In Python there are (too) many testing frameworks to choose from, all different. The original unit testing framework, included in Python by default, is the imaginatively named [unittest](https://docs.python.org/3/library/unittest.html) module. `unittest` talks about `test suites` comprising of related `test cases`, controlled by a `runner` and context managed by `fixtures`. There is no reason why we couldn't have something similar in APL if we wanted to build such a thing. But we probably want to find a more APL-y way of doing that.\n",
    "\n",
    "Here's what I'd want from my testing system:\n",
    "\n",
    "1. Ability to automatically run all tests, and get a report back on which tests succeeded.\n",
    "1. Ability to run a single test.\n",
    "1. Easy way to create more tests and have them be picked up by the test runner.\n",
    "\n",
    "Here's the first example from the `unittest` docs:\n",
    "\n",
    "```python\n",
    "import unittest\n",
    "\n",
    "class TestStringMethods(unittest.TestCase):\n",
    "\n",
    "    def test_upper(self):\n",
    "        self.assertEqual('foo'.upper(), 'FOO')\n",
    "\n",
    "    def test_isupper(self):\n",
    "        self.assertTrue('FOO'.isupper())\n",
    "        self.assertFalse('Foo'.isupper())\n",
    "\n",
    "    def test_split(self):\n",
    "        s = 'hello world'\n",
    "        self.assertEqual(s.split(), ['hello', 'world'])\n",
    "        # check that s.split fails when the separator is not a string\n",
    "        with self.assertRaises(TypeError):\n",
    "            s.split(2)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    unittest.main()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To add further tests, we just add methods starting with `test_` to the `TestStringMethods` class, and the `unittest.main()` method will run them for us. So for our first attempt, let's try to replicate that functionality in a Dyalog namespace. Here's our test runner, which simply executes all functions where the name starts with `test_` and produces a little report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    ":Namespace unittest\n",
    "    ⎕IO ← 0\n",
    "    run←{\n",
    "        tests ← 'test_.+'⎕S'&'⎕NL ¯3\n",
    "        0=≢tests: 'no tests found'\n",
    "        ↑{⍺,('.'/⍨30-≢⍺),⍵⊃'[FAIL]' '[OK]'}⌿↑tests (⍎¨tests,¨⊂' ⍬')\n",
    "    }\n",
    ":EndNamespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=\"white-space:pre; font-family: monospace\">no tests found\n",
       "</span>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unittest.run⍬"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make some functions that we can unit test. We can take the ones from the Python example above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "upper←1∘⎕C\n",
    "isupper←{⍵≡1⎕C⍵}\n",
    "split←≠⊆⊢         ⍝ Won't complain about a non-string separator, but hey, why should it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can write the tests themselves. Note that as in this case the functions we're testing are defined outside the `unittest` namespace, so we need to prefix the calls with `#.`. Note how we're using the test framework proposed by @ngn, outlined above :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "unittest.test_upper←{'FOO'≡#.upper 'foo'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=\"white-space:pre; font-family: monospace\">test_upper....................[OK]\n",
       "</span>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unittest.run⍬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "unittest.test_isupper←{(#.isupper 'FOO')∧~#.isupper 'Foo'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=\"white-space:pre; font-family: monospace\">test_isupper..................[OK]\n",
       "test_upper....................[OK]\n",
       "</span>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unittest.run⍬"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add a test that fails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "unittest.test_isupper2←{(#.isupper 'FOO')∧~#.isupper 'BAR'} ⍝ Failing test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=\"white-space:pre; font-family: monospace\">test_isupper..................[OK]  \n",
       "test_isupper2.................[FAIL]\n",
       "test_upper....................[OK]  \n",
       "</span>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unittest.run⍬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "unittest.test_split←{'hello' 'world'≡' '#.split 'hello world'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=\"white-space:pre; font-family: monospace\">test_isupper..................[OK]  \n",
       "test_isupper2.................[FAIL]\n",
       "test_split....................[OK]  \n",
       "test_upper....................[OK]  \n",
       "</span>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unittest.run⍬"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can of course run single tests trivially:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=\"white-space:pre; font-family: monospace\">1\n",
       "</span>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unittest.test_split⍬"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice, simple, and surprisingly useful.\n",
    "\n",
    "## Data-driven testing\n",
    "\n",
    "Data-driven testing, also known as parametrized testing, is where you provide essentially a table of inputs and expected outputs and let your testing framework run them all. This approach isn't supported out of the box in Python's basic `unittest` module. However, other more fully-featured Python frameworks, such as [pytest](https://docs.pytest.org/en/stable/parametrize.html#parametrize), do. \n",
    "\n",
    "Here's how that can look:\n",
    "\n",
    "```python\n",
    "import pytest\n",
    "\n",
    "@pytest.mark.parametrize(\"test_input,expected\", [(\"3+5\", 8), (\"2+4\", 6), (\"6*9\", 42)])\n",
    "def test_eval(test_input, expected):\n",
    "    assert eval(test_input) == expected\n",
    "```\n",
    "\n",
    "Here the decorator `@pytest.mark.parametrize` defines the test function arguments, and then provides a list of tuples. The test runner will then call the test function with the arguments as given by each tuple in turn. Let's see if we can achieve something similar in APL.\n",
    "\n",
    "This sounds like a job for an operator: we pass a _function_ to the test runner, and a vector of 3-\"tuples\" representing left argument, right argument and expected outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "_test←{(⊢/↑⍵)≡⍤0 0⊢⍺⍺/¯1↓⍤1⊢↑⍵}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=\"white-space:pre; font-family: monospace\">1 1\n",
       "</span>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split _test (' ' ('hello world') ('hello' 'world')) (',' ('hello,world') ('hello' 'world'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we need now is a convenient way to specify such parameter sets so they can be picked up by the test runner. We can do this by defining variables named `fn_testdata`, and have that be picked up by our unit testing namespace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_testdata←(' ' ('hello world') ('hello' 'world')) (',' ('hello,world') ('hello' 'world'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=\"white-space:pre; font-family: monospace\">1 1\n",
       "</span>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split _test split_testdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    ":Namespace datatest\n",
    "    ⎕IO ← 0\n",
    "    _test←{(⊢/↑⍵)≡⍤0 0⊢⍺⍺/¯1↓⍤1⊢↑⍵}\n",
    "    run←{ ⍝ ⍵ -- ns containing functions to be tested\n",
    "        params ← '_'(≠⊆⊢)¨'[^_]+_testdata'⎕S'&'⎕NL¯2.1    ⍝ https://aplcart.info/?q=%E2%8E%95NL#\n",
    "        0=≢params: 'no test parameter sets found'\n",
    "        funs ← ⊃¨↓¯1↓⍤1↑params                            ⍝ Corresponding functions defined?\n",
    "        testable ← funs/⍨funs∊⍵.⎕NL¯3\n",
    "        result←⍵∘{(⍺.⍎⍵)_test ⍎⍵,'_testdata'}¨testable    ⍝ Run the tests\n",
    "        ↑{⍺,('.'/⍨30-≢⍺),'[',(⍕+/⍵),'/',(⍕≢⍵),']'}⌿↑testable result ⍝ Format\n",
    "    }\n",
    ":EndNamespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "datatest.split_testdata←(' ' ('hello world') ('hello' 'world')) (',' ('hello,world') ('hello' 'world')) ⍝ dyadic function\n",
    "datatest.isupper_testdata←(⍬ ('FOO') 1) (⍬ ('Foo') 0) (⍬ (,'F') 1) ⍝ monadic function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=\"white-space:pre; font-family: monospace\">isupper.......................[3/3]\n",
       "split.........................[2/2]\n",
       "</span>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datatest.run ⎕THIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So there we have it. Of course, in a real project you may want a slightly more fleshed out test framework, capable of testing for exceptions etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Dyalog APL",
   "language": "apl",
   "name": "dyalog-kernel"
  },
  "language_info": {
   "file_extension": ".apl",
   "mimetype": "text/apl",
   "name": "APL"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
